---
title: Databricksでファイル名を取り込む方法
tags:
  - Microsoft
  - Azure
  - Databricks
private: false
updated_at: '2022-09-22T13:34:03+09:00'
id: df86fb6d1ba4658f474e
organization_url_name: null
slide: false
---
## はじめに

Databricksでデータを取り込む際に、取り込み元ファイルの情報も取得する方法をまとめます。


### 非Unity Catalog環境


input_file_name()を使用します。

[pyspark.sql.functions.input_file_name](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.input_file_name.html)

```pyspark:pyspark

from  pyspark.sql.functions import input_file_name,current_timestamp
df = (spark
        .read
        .format("csv")
        .load(<ファイルパス>)
        .select("*"
            ,current_timestamp().alias("_ingest_timestamp")
            ,input_file_name().alias("_file_name")
        )
     )

```

こんな感じでとれます。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281819/38bd0240-fbbc-636b-92db-e96e9d2bcf01.png)


### Unity Catalog環境下

以下のようにサポートされない旨が表示されます。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281819/92a5adc5-fdeb-73a5-e86d-ed5534e65f16.png)



[ファイル メタデータ列](https://learn.microsoft.com/ja-jp/azure/databricks/ingestion/file-metadata-column) という形で取得が可能です。

例：

```pyspark:pyspark

df = (spark
        .read
        .format("csv")
        .load(<ファイルパス>)
        .select("*","_metadata")
     )

```

こんな感じでとれます。


![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281819/8a0039ca-e08a-f3f6-7fd1-bcdf9b1ae409.png)

#### 追記

シングルユーザーモードであればUnity Catalog 環境でもinput_file_nameが動作しました。
autoloaderといい、pythonの関数はけっこうこういうのが多いみたいです。

![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281819/b4b7932d-bdd4-fcad-c1f9-18285b0ea01f.png)
