{
  "metadata": {
    "saveOutput": true,
    "kernelspec": {
      "name": "python3-azureml",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Predict NYC Taxi Tips \r\n",
        "The notebook ingests, prepares and then trains a model based on an Open Dataset that tracks NYC Yellow Taxi trips and various attributes around them. The goal is to for a given trip, predict whether there will be a tip or not. The model then will be converted to ONNX format and tracked by MLFlow.\r\n",
        "We will later use the ONNX model for inferencing in Azure Synapse SQL Pool using the new model scoring wizard.\r\n",
        "## Note:\r\n",
        "**Please note that for successful conversion to ONNX, this notebook requires using  Scikit-learn version 0.20.3.**\r\n",
        "Run the first cell to list the packages installed and check your sklearn version. Uncomment the pip install command to install the correct version\r\n",
        "\r\n",
        "%pip install scikit-learn==0.20.3\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Load data\r\n",
        "Get a sample data of nyc yellow taxi from Azure Open Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "#%pip list\n",
        "#%pip install scikit-learn==0.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00000-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426339-118.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00001-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426336-117.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00002-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426334-119.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00003-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426340-115.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00004-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426331-116.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00005-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426324-117.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00006-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426326-116.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00007-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426332-118.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00008-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426341-118.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00009-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426325-116.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00010-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426335-117.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00011-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426338-117.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00012-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426337-117.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00013-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426327-117.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00014-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426330-118.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00015-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426342-117.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00016-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426328-116.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00017-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426323-118.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00018-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426329-118.c000.snappy.parquet\n[Info] read from /tmp/tmp8403w7ap/https/azureopendatastorage.azurefd.net/nyctlc/yellow/puYear=2018/puMonth=5/part-00019-tid-8898858832658823408-a1de80bd-eed3-4d11-b9d4-fa74bfbd47bc-426333-116.c000.snappy.parquet\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1909118 entries, 12 to 405777\nData columns (total 21 columns):\n #   Column                Dtype         \n---  ------                -----         \n 0   vendorID              object        \n 1   tpepPickupDateTime    datetime64[ns]\n 2   tpepDropoffDateTime   datetime64[ns]\n 3   passengerCount        int32         \n 4   tripDistance          float64       \n 5   puLocationId          object        \n 6   doLocationId          object        \n 7   startLon              float64       \n 8   startLat              float64       \n 9   endLon                float64       \n 10  endLat                float64       \n 11  rateCodeId            int32         \n 12  storeAndFwdFlag       object        \n 13  paymentType           object        \n 14  fareAmount            float64       \n 15  extra                 float64       \n 16  mtaTax                float64       \n 17  improvementSurcharge  object        \n 18  tipAmount             float64       \n 19  tollsAmount           float64       \n 20  totalAmount           float64       \ndtypes: datetime64[ns](2), float64(11), int32(2), object(6)\nmemory usage: 305.9+ MB"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1599713958224
        }
      },
      "source": [
        "from azureml.opendatasets import NycTlcYellow\r\n",
        "from datetime import datetime\r\n",
        "from dateutil import parser\r\n",
        "\r\n",
        "start_date = parser.parse('2018-05-01')\r\n",
        "end_date = parser.parse('2018-05-07')\r\n",
        "nyc_tlc = NycTlcYellow(start_date=start_date, end_date=end_date)\r\n",
        "nyc_tlc_df = nyc_tlc.to_pandas_dataframe()\r\n",
        "nyc_tlc_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "vendorID  tpepPickupDateTime  ... tollsAmount  totalAmount\n87213         2 2018-05-05 19:07:01  ...        5.76        23.56\n145405        2 2018-05-05 22:46:06  ...        0.00        12.96\n457648        1 2018-05-06 18:53:06  ...        0.00        11.80\n369051        2 2018-05-02 09:25:13  ...        0.00        10.56\n38871         2 2018-05-04 02:58:10  ...        0.00         6.62\n\n[5 rows x 21 columns]"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1599713959314
        },
        "collapsed": true
      },
      "source": [
        "from IPython.display import display\r\n",
        "\r\n",
        "sampled_df = nyc_tlc_df.sample(n=10000, random_state=123)\r\n",
        "display(sampled_df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Prepare and featurize data\r\n",
        "- There are extra dimensions that are not going to be useful in the model. We just take the dimensions that we need and put them into the featurised dataframe. \r\n",
        "- There are also a bunch of outliers in the data so we need to filter them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "tipped  fareAmount  ...  tripTimeSecs  pickupTimeBin\n87213        0        17.0  ...          1303         PMRush\n145405       1         9.5  ...           785          Night\n457648       0        11.0  ...           805         PMRush\n369051       1         8.0  ...           679         AMRush\n38871        1         4.0  ...           180          Night\n\n[5 rows x 7 columns]"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1599713966451
        },
        "collapsed": true
      },
      "source": [
        "import numpy\r\n",
        "import pandas\r\n",
        "\r\n",
        "def get_pickup_time(df):\r\n",
        "    pickupHour = df['pickupHour'];\r\n",
        "    if ((pickupHour >= 7) & (pickupHour <= 10)):\r\n",
        "        return 'AMRush'\r\n",
        "    elif ((pickupHour >= 11) & (pickupHour <= 15)):\r\n",
        "        return 'Afternoon'\r\n",
        "    elif ((pickupHour >= 16) & (pickupHour <= 19)):\r\n",
        "        return 'PMRush'\r\n",
        "    else:\r\n",
        "        return 'Night'\r\n",
        "\r\n",
        "featurized_df = pandas.DataFrame()\r\n",
        "featurized_df['tipped'] = (sampled_df['tipAmount'] > 0).astype('int')\r\n",
        "featurized_df['fareAmount'] = sampled_df['fareAmount'].astype('float32')\r\n",
        "featurized_df['paymentType'] = sampled_df['paymentType'].astype('int')\r\n",
        "featurized_df['passengerCount'] = sampled_df['passengerCount'].astype('int')\r\n",
        "featurized_df['tripDistance'] = sampled_df['tripDistance'].astype('float32')\r\n",
        "featurized_df['pickupHour'] = sampled_df['tpepPickupDateTime'].dt.hour.astype('int')\r\n",
        "featurized_df['tripTimeSecs'] = ((sampled_df['tpepDropoffDateTime'] - sampled_df['tpepPickupDateTime']) / numpy.timedelta64(1, 's')).astype('int')\r\n",
        "\r\n",
        "featurized_df['pickupTimeBin'] = featurized_df.apply(get_pickup_time, axis=1)\r\n",
        "featurized_df = featurized_df.drop(columns='pickupHour')\r\n",
        "\r\n",
        "display(featurized_df.head(5))\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 9776 entries, 87213 to 333274\nData columns (total 7 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   tipped          9776 non-null   int64  \n 1   fareAmount      9776 non-null   float32\n 2   paymentType     9776 non-null   int64  \n 3   passengerCount  9776 non-null   int64  \n 4   tripDistance    9776 non-null   float32\n 5   tripTimeSecs    9776 non-null   int64  \n 6   pickupTimeBin   9776 non-null   object \ndtypes: float32(2), int64(4), object(1)\nmemory usage: 534.6+ KB"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1599713971477
        },
        "collapsed": true
      },
      "source": [
        "filtered_df = featurized_df[(featurized_df.tipped >= 0) & (featurized_df.tipped <= 1)\\\r\n",
        "    & (featurized_df.fareAmount >= 1) & (featurized_df.fareAmount <= 250)\\\r\n",
        "    & (featurized_df.paymentType >= 1) & (featurized_df.paymentType <= 2)\\\r\n",
        "    & (featurized_df.passengerCount > 0) & (featurized_df.passengerCount < 8)\\\r\n",
        "    & (featurized_df.tripDistance >= 0) & (featurized_df.tripDistance <= 100)\\\r\n",
        "    & (featurized_df.tripTimeSecs >= 30) & (featurized_df.tripTimeSecs <= 7200)]\r\n",
        "\r\n",
        "filtered_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Split training and testing data sets\r\n",
        "- 70% of the data is used to train the model.\r\n",
        "- 30% of the data is used to test the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1599713980823
        },
        "collapsed": true
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "train_df, test_df = train_test_split(filtered_df, test_size=0.3, random_state=123)\r\n",
        "\r\n",
        "x_train = pandas.DataFrame(train_df.drop(['tipped'], axis = 1))\r\n",
        "y_train = pandas.DataFrame(train_df.iloc[:,train_df.columns.tolist().index('tipped')])\r\n",
        "\r\n",
        "x_test = pandas.DataFrame(test_df.drop(['tipped'], axis = 1))\r\n",
        "y_test = pandas.DataFrame(test_df.iloc[:,test_df.columns.tolist().index('tipped')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Export test data as CSV\r\n",
        "Export the test data as a CSV file. Later, we will load the CSV file into Synapse SQL pool to test the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1598830320180
        },
        "collapsed": true
      },
      "source": [
        "test_df.to_csv('test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Train model\r\n",
        "Train a bi-classifier to predict whether a taxi trip will be a tipped or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "Pipeline(memory=None,\n     steps=[('preprocessor', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n         transformer_weights=None,\n         transformers=[('float', Pipeline(memory=None,\n     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n       strategy='median', ver...enalty='l2', random_state=None, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False))])\n/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1599713996871
        },
        "collapsed": true
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
        "\r\n",
        "float_features = ['fareAmount', 'tripDistance']\r\n",
        "float_transformer = Pipeline(steps=[\r\n",
        "    ('imputer', SimpleImputer(strategy='median')),\r\n",
        "    ('scaler', StandardScaler())])\r\n",
        "\r\n",
        "integer_features = ['paymentType', 'passengerCount', 'tripTimeSecs']\r\n",
        "integer_transformer = Pipeline(steps=[\r\n",
        "    ('imputer', SimpleImputer(strategy='median')),\r\n",
        "    ('scaler', StandardScaler())])\r\n",
        "\r\n",
        "categorical_features = ['pickupTimeBin']\r\n",
        "categorical_transformer = Pipeline(steps=[\r\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\r\n",
        "\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "        ('float', float_transformer, float_features),\r\n",
        "        ('integer', integer_transformer, integer_features),\r\n",
        "        ('cat', categorical_transformer, categorical_features)\r\n",
        "    ])\r\n",
        "\r\n",
        "clf = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
        "                      ('classifier', LogisticRegression(solver='lbfgs'))])\r\n",
        "\r\n",
        "# Train the model\r\n",
        "clf.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "0.9672690078418003"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1599714001990
        },
        "collapsed": true
      },
      "source": [
        "# Evalute the model\r\n",
        "score = clf.score(x_test, y_test)\r\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Convert the model to ONNX format\r\n",
        "Currently, T-SQL scoring only supports ONNX model format (https://onnx.ai/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1598830324781
        },
        "collapsed": true
      },
      "source": [
        "from skl2onnx import convert_sklearn\r\n",
        "from skl2onnx.common.data_types import FloatTensorType, Int64TensorType, DoubleTensorType, StringTensorType\r\n",
        "\r\n",
        "def convert_dataframe_schema(df, drop=None):\r\n",
        "    inputs = []\r\n",
        "    for k, v in zip(df.columns, df.dtypes):\r\n",
        "        if drop is not None and k in drop:\r\n",
        "            continue\r\n",
        "        if v == 'int64':\r\n",
        "            t = Int64TensorType([1, 1])\r\n",
        "        elif v == 'float32':\r\n",
        "            t = FloatTensorType([1, 1])\r\n",
        "        elif v == 'float64':\r\n",
        "            t = DoubleTensorType([1, 1])\r\n",
        "        else:\r\n",
        "            t = StringTensorType([1, 1])\r\n",
        "        inputs.append((k, t))\r\n",
        "    return inputs\r\n",
        "\r\n",
        "model_inputs = convert_dataframe_schema(x_train)\r\n",
        "onnx_model = convert_sklearn(clf, \"nyc_taxi_tip_predict\", model_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Register the model with MLFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1598830390704
        },
        "collapsed": true
      },
      "source": [
        "# Azure MLと接続\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.get(name=\"mlverify-mlws\",\n",
        "            subscription_id='a1d6eb75-4814-4275-8647-9addeb8fe6e3',\n",
        "            resource_group='BAP-ZEALWorkshop-RG-01-Prd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "INFO: 'nyc_taxi_tip_predict_exp' does not exist. Creating a new experiment\n<ModelVersion: creation_timestamp=1603187804853, current_stage='None', description='', last_updated_timestamp=1603187804853, name='nyc_taxi_tip_predict', run_id='a415d769-1258-4d6f-a7ec-e076cce93cc8', run_link='', source='azureml://experiments/nyc_taxi_tip_predict_exp/runs/a415d769-1258-4d6f-a7ec-e076cce93cc8/artifacts/nyc_taxi_tip_predict_artifact', status='READY', status_message='', tags={}, user_id='', version='1'>\n2020/10/20 09:56:43 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under azureml://experiments/nyc_taxi_tip_predict_exp/runs/a415d769-1258-4d6f-a7ec-e076cce93cc8/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\nSuccessfully registered model 'nyc_taxi_tip_predict'.\nCreated version '1' of model 'nyc_taxi_tip_predict'."
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1598830404736
        },
        "collapsed": true
      },
      "source": [
        "import mlflow\r\n",
        "import mlflow.onnx\r\n",
        "\r\n",
        "from mlflow.models.signature import infer_signature\r\n",
        "\r\n",
        "experiment_name = 'nyc_taxi_tip_predict_exp'\r\n",
        "artifact_path = 'nyc_taxi_tip_predict_artifact'\r\n",
        "\r\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\r\n",
        "mlflow.set_experiment(experiment_name)\r\n",
        "\r\n",
        "with mlflow.start_run() as run:\r\n",
        "    # Infer signature\r\n",
        "    input_sample = x_train.head(1)\r\n",
        "    output_sample = pandas.DataFrame(columns=['output_label'], data=[1])\r\n",
        "    signature = infer_signature(input_sample, output_sample)\r\n",
        "\r\n",
        "    # Save the model to the outputs directory for capture\r\n",
        "    mlflow.onnx.log_model(onnx_model, artifact_path, signature=signature, input_example=input_sample)\r\n",
        "\r\n",
        "    # Register the model to AML model registry\r\n",
        "    mlflow.register_model('runs:/' + run.info.run_id + '/' + artifact_path, 'nyc_taxi_tip_predict')\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {},
      "source": [],
      "attachments": {}
    }
  ]
}